{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "history_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thisisanu/online_deep_learning/blob/main/homework3/Homework3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bov3RYkG8VWh",
        "outputId": "93498193-958c-4ff2-f33d-991e3b32b09a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Nov 10 00:11:30 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   54C    P8             10W /   70W |       2MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "torch.cuda.is_available()\n",
        "!nvidia-smi\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Ensure we are in /content\n",
        "os.chdir(\"/content\")\n",
        "print(\"Current directory:\", os.getcwd())\n",
        "\n",
        "# If a folder named homework2 exists, remove it completely\n",
        "if os.path.exists(\"online_deep_learning\"):\n",
        "    shutil.rmtree(\"online_deep_learning\")\n",
        "    print(\"Old online_deep_learning folder removed.\")\n",
        "else:\n",
        "    print(\"No existing online_deep_learning folder found.\")\n",
        "\n",
        "!git clone https://github.com/thisisanu/online_deep_learning.git\n",
        "%cd online_deep_learning/homework3\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekl-7BPR83PV",
        "outputId": "b0cffcfe-193a-4e04-fb6a-d47a173b1a71"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current directory: /content\n",
            "Old online_deep_learning folder removed.\n",
            "Cloning into 'online_deep_learning'...\n",
            "remote: Enumerating objects: 501, done.\u001b[K\n",
            "remote: Counting objects: 100% (206/206), done.\u001b[K\n",
            "remote: Compressing objects: 100% (198/198), done.\u001b[K\n",
            "remote: Total 501 (delta 137), reused 27 (delta 6), pack-reused 295 (from 2)\u001b[K\n",
            "Receiving objects: 100% (501/501), 3.06 MiB | 21.76 MiB/s, done.\n",
            "Resolving deltas: 100% (324/324), done.\n",
            "/content/online_deep_learning/homework3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy torch torchvision tqdm matplotlib\n",
        "\n",
        "#download the datasets by running the following command from the main directory\n",
        "!curl -s -L https://www.cs.utexas.edu/~bzhou/dl_class/classification_data.zip -o ./classification_data.zip && unzip -qo classification_data.zip\n",
        "!curl -s -L https://www.cs.utexas.edu/~bzhou/dl_class/drive_data.zip -o ./drive_data.zip && unzip -qo drive_data.zip\n",
        "!ls\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybDIPCfnaOSf",
        "outputId": "96f5eec5-56df-4907-bced-e1d9aba10123"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "bundle.py\t\t drive_data\t homework\t  requirements.txt\n",
            "classification_data\t drive_data.zip  Homework3.ipynb\n",
            "classification_data.zip  grader\t\t README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n",
        "!python3 -m grader homework -v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFiQJezGcs1u",
        "outputId": "c0dd6b28-be9c-4034-d157-d52b10a64c63"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bundle.py\t\t drive_data\t homework\t  requirements.txt\n",
            "classification_data\t drive_data.zip  Homework3.ipynb\n",
            "classification_data.zip  grader\t\t README.md\n",
            "Public grader loaded.\n",
            "\u001b[97m[INFO     00:00:001] \u001b[0m\u001b[97mClassifier\u001b[0m\n",
            "\u001b[97m[INFO     00:00:501] \u001b[0m\u001b[97m  - Predict                                            [ 10 / 10 ]\u001b[0m\n",
            "\u001b[33m[WARNING  00:00:531] \u001b[0m\u001b[33m  - Accuracy                                           [ 0 / 25 ]\u001b[0m\n",
            "\u001b[33m[WARNING  00:00:531] \u001b[0m\u001b[33mclassifier.th not found\u001b[0m\n",
            "\u001b[33m[WARNING  00:00:555] \u001b[0m\u001b[33m  - Accuracy: Extra Credit                             [ 0 / 2 ]\u001b[0m\n",
            "\u001b[33m[WARNING  00:00:555] \u001b[0m\u001b[33mclassifier.th not found\u001b[0m\n",
            "\u001b[97m[INFO     00:00:556] \u001b[0m\u001b[97m --------------------------------------------------    [  10 /  35 ]\u001b[0m\n",
            "\u001b[97m[INFO     00:00:557] \u001b[0m\u001b[97mDetector\u001b[0m\n",
            "\u001b[97m[INFO     00:00:603] \u001b[0m\u001b[97m  - Predict                                            [ 10 / 10 ]\u001b[0m\n",
            "\u001b[33m[WARNING  00:00:604] \u001b[0m\u001b[33m  - Segmentation Accuracy                              [ 0 / 10 ]\u001b[0m\n",
            "\u001b[33m[WARNING  00:00:604] \u001b[0m\u001b[33mdetector.th not found\u001b[0m\n",
            "\u001b[33m[WARNING  00:00:604] \u001b[0m\u001b[33m  - Segmentation IoU                                   [ 0 / 25 ]\u001b[0m\n",
            "\u001b[33m[WARNING  00:00:604] \u001b[0m\u001b[33mdetector.th not found\u001b[0m\n",
            "\u001b[33m[WARNING  00:00:604] \u001b[0m\u001b[33m  - Segmentation IoU: Extra Credit                     [ 0 / 2 ]\u001b[0m\n",
            "\u001b[33m[WARNING  00:00:604] \u001b[0m\u001b[33mdetector.th not found\u001b[0m\n",
            "\u001b[33m[WARNING  00:00:604] \u001b[0m\u001b[33m  - Depth Error                                        [ 0 / 10 ]\u001b[0m\n",
            "\u001b[33m[WARNING  00:00:604] \u001b[0m\u001b[33mdetector.th not found\u001b[0m\n",
            "\u001b[33m[WARNING  00:00:605] \u001b[0m\u001b[33m  - Depth Error: Extra Credit                          [ 0 / 2 ]\u001b[0m\n",
            "\u001b[33m[WARNING  00:00:605] \u001b[0m\u001b[33mdetector.th not found\u001b[0m\n",
            "\u001b[33m[WARNING  00:00:605] \u001b[0m\u001b[33m  - True Positives Depth Error                         [ 0 / 10 ]\u001b[0m\n",
            "\u001b[33m[WARNING  00:00:605] \u001b[0m\u001b[33mdetector.th not found\u001b[0m\n",
            "\u001b[97m[INFO     00:00:605] \u001b[0m\u001b[97m --------------------------------------------------    [  10 /  65 ]\u001b[0m\n",
            "\u001b[97m[INFO     00:00:605] \u001b[0m\u001b[97mTotal                                                     20 / 100\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "101b4b4b"
      },
      "source": [
        "# Task\n",
        "Implement and train a classification model, saving the trained model as `classifier.th`. Subsequently, implement and train an object detection model, saving the trained model as `detector.th`. Conclude by confirming the successful generation of both `classifier.th` and `detector.th` files."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14eb21f4"
      },
      "source": [
        "The subtask requires creating a new Python file `train_classification.py` and adding initial setup code for imports, device configuration, data transformations, and data loading. This code block will create the file and include all the necessary components as specified in the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c063a596",
        "outputId": "efcc4077-464d-4389-a224-b37196ba2bd4"
      },
      "source": [
        "import os\n",
        "\n",
        "# The content that will be written to train_classification.py\n",
        "# This string contains all the necessary imports, function definitions,\n",
        "# and the main execution block for the classification training setup.\n",
        "file_content = \"\"\"\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "import argparse\n",
        "\n",
        "# Device configuration\n",
        "def setup_device():\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Using device: {device}\")\n",
        "    return device\n",
        "\n",
        "# Data transformations\n",
        "def get_data_transforms(image_size):\n",
        "    data_transforms = {\n",
        "        'train': transforms.Compose([\n",
        "            transforms.Resize(image_size),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ]),\n",
        "        'val': transforms.Compose([\n",
        "            transforms.Resize(image_size),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ]),\n",
        "    }\n",
        "    return data_transforms\n",
        "\n",
        "# Data loading\n",
        "def get_data_loaders(data_dir, data_transforms, batch_size):\n",
        "    image_datasets = {\n",
        "        x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x])\n",
        "        for x in ['train', 'val']\n",
        "    }\n",
        "    dataloaders = {\n",
        "        x: DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "        for x in ['train', 'val']\n",
        "    }\n",
        "    dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "    class_names = image_datasets['train'].classes\n",
        "    print(f\"Found {dataset_sizes['train']} training images and {dataset_sizes['val']} validation images.\")\n",
        "    print(f\"Classes: {class_names}\")\n",
        "    return dataloaders, dataset_sizes, class_names\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    parser = argparse.ArgumentParser(description='Classification Training Setup')\n",
        "    parser.add_argument('--data_dir', type=str, default='./classification_data', help='Directory with classification data')\n",
        "    parser.add_argument('--batch_size', type=int, default=32, help='Batch size for data loaders')\n",
        "    parser.add_argument('--image_size', type=int, default=224, help='Image size for resizing')\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    device = setup_device()\n",
        "    data_transforms = get_data_transforms(args.image_size)\n",
        "    dataloaders, dataset_sizes, class_names = get_data_loaders(args.data_dir, data_transforms, args.batch_size)\n",
        "\n",
        "    # Example of how to access data\n",
        "    # inputs, labels = next(iter(dataloaders['train']))\n",
        "    # print(f\"Batch input shape: {inputs.shape}\")\n",
        "    # print(f\"Batch labels shape: {labels.shape}\")\n",
        "\n",
        "    print(\"Classification training setup complete.\")\n",
        "\"\"\"\n",
        "\n",
        "# Write the content to the file\n",
        "with open('train_classification.py', 'w') as f:\n",
        "    f.write(file_content)\n",
        "print(\"Created train_classification.py with initial setup code.\")\n",
        "print(\"Initial classification training setup components are ready in train_classification.py.\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created train_classification.py with initial setup code.\n",
            "Initial classification training setup components are ready in train_classification.py.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93d47b97"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous steps successfully created the `train_classification.py` file. Now, to verify its functionality and ensure the initial setup components (device config, data transforms, data loading) are correctly integrated, I will execute the script. This will confirm that the file is executable and performs the expected setup operations.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "65135037",
        "outputId": "a54be3d4-4881-44cd-be7e-4392abe5f7cb"
      },
      "source": [
        "import os\n",
        "\n",
        "import os\n",
        "print(os.listdir('./classification_data'))\n",
        "print(os.listdir('./classification_data/train'))\n",
        "print(os.listdir('./classification_data/val'))\n",
        "\n",
        "\n",
        "print(\"Verifying train_classification.py setup...\")\n",
        "!python train_classification.py --data_dir ./classification_data\n",
        "print(\"Verification complete.\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: './classification_data'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1586410592.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./classification_data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./classification_data/train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./classification_data/val'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './classification_data'"
          ]
        }
      ]
    }
  ]
}