{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zWseivb1lli"
      },
      "source": [
        "## General Colab Tips\n",
        "- Modify files by opening/editing them in the UI (double-click to open).\n",
        "- `Right click > Refresh` in the Colab file explorer to update the directory.\n",
        "- All files are lost when the Colab session disconnects, so make sure back up your work.\n",
        "- Do **not** use `drive.mount` for your datasets! Reading from GDrive is super slow.\n",
        "- Instead, place datasets into the `/content/` folder and modify your data accordingly.\n",
        "\n",
        "**Make a copy of this notebook and modify this to whatever workflow you prefer!**\n",
        "\n",
        "If you have some additional colab tips, please share them on the discussion forum.\n",
        "\n",
        "## Setup\n",
        "\n",
        "First, enable a GPU runtime via `Runtime > Change runtime type > T4 GPU`\n",
        "\n",
        "Next, upload the your project files to the Colab. You can do this by either\n",
        "- using Github (**recommended**)\n",
        "- uploading files manually using the UI\n",
        "\n",
        "## Github Setup\n",
        "\n",
        "You can use git from within Google Colab!\n",
        "\n",
        "For this section, we assume you know how to use git and have already pushed the starter code to a private repo.\n",
        "\n",
        "Before you continue, make sure you download and push the starter code to your repo.  \n",
        "It's a good idea to structure your repo something like\n",
        "```\n",
        "online_deep_learning/\n",
        "    homework1/\n",
        "    homework2/\n",
        "    ...\n",
        "```\n",
        "\n",
        "We highly recommend using this workflow as you'll be able to easily pull/commit your changes after modifying your model on Colab.\n",
        "\n",
        "To do this, you'll need a personal access token from [https://github.com/settings/tokens](https://github.com/settings/tokens)\n",
        "\n",
        "The easiest thing to do is select \"classic\" token and make sure you have the `repo` scope selected to allow access to your private repos.\n",
        "There's also fine-grained tokens where you can select access to specific repos.\n",
        "\n",
        "Once you have your token, fill in your information and then run the following cell to clone your git repo to the Colab instance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "vLC51taXudfJ",
        "outputId": "7b046809-58b6-4df5-c855-53c0705df3c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
            "/content\n",
            "Cloning into 'online_deep_learning'...\n",
            "remote: Enumerating objects: 1365, done.\u001b[K\n",
            "remote: Counting objects: 100% (64/64), done.\u001b[K\n",
            "remote: Compressing objects: 100% (63/63), done.\u001b[K\n",
            "remote: Total 1365 (delta 45), reused 1 (delta 1), pack-reused 1301 (from 5)\u001b[K\n",
            "Receiving objects: 100% (1365/1365), 3.83 MiB | 9.46 MiB/s, done.\n",
            "Resolving deltas: 100% (954/954), done.\n",
            "\u001b[0m\u001b[01;34monline_deep_learning\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "\n",
        "os.environ['USER'] = 'thisisanu'\n",
        "os.environ['REPO'] = 'online_deep_learning'\n",
        "os.environ['TOKEN'] = 'ithub_pat_11BIG54WA0sAoSEImPXImB_OUcAjo84vwWTugnGOH4GbPnqToNKRJESKhyxDDzjYYUDQXP7HGCBmOPHCVt'\n",
        "\n",
        "# do everything in colab's \"root\" directory\n",
        "!rm -rf /content/online_deep_learning\n",
        "!rm -rf /content/online_deep_learning/homework4\n",
        "\n",
        "%cd /content\n",
        "!git clone https://${TOKEN}@github.com/${USER}/${REPO}.git\n",
        "\n",
        "# make sure your repo shows up\n",
        "%ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gxzo13BN6FL0"
      },
      "source": [
        "## Code Setup\n",
        "\n",
        "Move into `homework4/` so we can continue setting up the data / code for training.\n",
        "\n",
        "This will be the main working directory and the training/grading must be run from this directory.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "et3KFSXs3IHk",
        "outputId": "5a03b957-1975-4976-e0cf-75bd7ee43331",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/online_deep_learning\n",
            "gitignore  \u001b[0m\u001b[01;34mhomework1\u001b[0m/  \u001b[01;34mhomework2\u001b[0m/  \u001b[01;34mhomework3\u001b[0m/  \u001b[01;34mhomework4\u001b[0m/  README.md\n",
            "/content/online_deep_learning/homework4\n",
            "\u001b[0m\u001b[01;34massets\u001b[0m/    \u001b[01;34mgrader\u001b[0m/    Homework_4.ipynb  requirements.txt\n",
            "bundle.py  \u001b[01;34mhomework\u001b[0m/  README.md\n"
          ]
        }
      ],
      "source": [
        "# navigate to your repo\n",
        "%cd /content/{os.environ['REPO']}\n",
        "%ls\n",
        "\n",
        "# go to a specific homework\n",
        "%cd homework4\n",
        "%ls\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnjXUhBY7x_E"
      },
      "source": [
        "## Dataset Setup\n",
        "\n",
        "Now that your code is all ready, the next step is to download the datasets.\n",
        "\n",
        "Note: it's good practice to add data directories like `*/drive_data` to your `.gitignore` so you don't accidently commit them to your repo.\n",
        "\n",
        "Since the datasets used in this class are relatively small, we can simply re-download them if the compute instance crashes/restarts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "RmMw_Zoa8Ljm",
        "outputId": "047888d8-b4a9-4ae7-be89-9c3feadb53ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34massets\u001b[0m/    \u001b[01;34mdrive_data\u001b[0m/     \u001b[01;34mgrader\u001b[0m/    Homework_4.ipynb  requirements.txt\n",
            "bundle.py  drive_data.zip  \u001b[01;34mhomework\u001b[0m/  README.md\n"
          ]
        }
      ],
      "source": [
        "!rm -rf drive_data\n",
        "!curl -s -L https://www.cs.utexas.edu/~bzhou/dl_class/drive_data.zip -o ./drive_data.zip && unzip -qo drive_data.zip\n",
        "%ls\n",
        "\n",
        "import sys\n",
        "import torch\n",
        "\n",
        "!{sys.executable} -m pip install -r requirements.txt\n",
        "!{sys.executable} -m pip install --upgrade \"ipython>=8.20.0\"\n",
        "\n",
        "print(\"Python:\", sys.version)\n",
        "print(\"Executable:\", sys.executable)\n",
        "\n",
        "!pip show ipython"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUR0D6BsJP49"
      },
      "source": [
        "## Model Implementation + Training\n",
        "\n",
        "Now you should be all set up.\n",
        "Next, you'll need to implement\n",
        "- `homework/train_planner.py`\n",
        "- `homework/models.py`\n",
        "\n",
        "And then you're ready to train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "WLe2Ti0xJeIL",
        "outputId": "4bac96f9-c331-448d-df4b-bc5c265b1b88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (3.10.0)\n",
            "Requirement already satisfied: Pillow>=10.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (11.3.0)\n",
            "Requirement already satisfied: tensorboard>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (2.19.0)\n",
            "Requirement already satisfied: termcolor==2.4.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (2.4.0)\n",
            "Requirement already satisfied: opencv-python>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (4.12.0.88)\n",
            "Requirement already satisfied: tqdm==4.66.4 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (4.66.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.5.0->-r requirements.txt (line 1)) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.5.0->-r requirements.txt (line 1)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.5.0->-r requirements.txt (line 1)) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.5.0->-r requirements.txt (line 1)) (1.4.9)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.5.0->-r requirements.txt (line 1)) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.5.0->-r requirements.txt (line 1)) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.5.0->-r requirements.txt (line 1)) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.5.0->-r requirements.txt (line 1)) (2.9.0.post0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.0.0->-r requirements.txt (line 3)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.0.0->-r requirements.txt (line 3)) (1.76.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.0.0->-r requirements.txt (line 3)) (3.10)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.0.0->-r requirements.txt (line 3)) (5.29.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.0.0->-r requirements.txt (line 3)) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.0.0->-r requirements.txt (line 3)) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.0.0->-r requirements.txt (line 3)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.0.0->-r requirements.txt (line 3)) (3.1.3)\n",
            "Requirement already satisfied: typing-extensions~=4.12 in /usr/local/lib/python3.12/dist-packages (from grpcio>=1.48.2->tensorboard>=2.0.0->-r requirements.txt (line 3)) (4.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.0.0->-r requirements.txt (line 3)) (3.0.3)\n",
            "Requirement already satisfied: ipython>=8.20.0 in /usr/local/lib/python3.12/dist-packages (9.7.0)\n",
            "Requirement already satisfied: decorator>=4.3.2 in /usr/local/lib/python3.12/dist-packages (from ipython>=8.20.0) (4.4.2)\n",
            "Requirement already satisfied: ipython-pygments-lexers>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython>=8.20.0) (1.1.1)\n",
            "Requirement already satisfied: jedi>=0.18.1 in /usr/local/lib/python3.12/dist-packages (from ipython>=8.20.0) (0.19.2)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1.5 in /usr/local/lib/python3.12/dist-packages (from ipython>=8.20.0) (0.2.1)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython>=8.20.0) (4.9.0)\n",
            "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /usr/local/lib/python3.12/dist-packages (from ipython>=8.20.0) (3.0.52)\n",
            "Requirement already satisfied: pygments>=2.11.0 in /usr/local/lib/python3.12/dist-packages (from ipython>=8.20.0) (2.19.2)\n",
            "Requirement already satisfied: stack_data>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from ipython>=8.20.0) (0.6.3)\n",
            "Requirement already satisfied: traitlets>=5.13.0 in /usr/local/lib/python3.12/dist-packages (from ipython>=8.20.0) (5.14.3)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.18.1->ipython>=8.20.0) (0.8.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython>=8.20.0) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=8.20.0) (0.2.14)\n",
            "Requirement already satisfied: executing>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from stack_data>=0.6.0->ipython>=8.20.0) (2.2.1)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from stack_data>=0.6.0->ipython>=8.20.0) (3.0.1)\n",
            "Requirement already satisfied: pure-eval in /usr/local/lib/python3.12/dist-packages (from stack_data>=0.6.0->ipython>=8.20.0) (0.2.3)\n",
            "Python: 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n",
            "Executable: /usr/bin/python3\n",
            "Name: ipython\n",
            "Version: 9.7.0\n",
            "Summary: IPython: Productive Interactive Computing\n",
            "Home-page: https://ipython.org\n",
            "Author: The IPython Development Team\n",
            "Author-email: ipython-dev@python.org\n",
            "License: \n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: decorator, ipython-pygments-lexers, jedi, matplotlib-inline, pexpect, prompt_toolkit, pygments, stack_data, traitlets\n",
            "Required-by: bigquery-magics, cufflinks, google-colab, ipykernel, ipyparallel, ipython-sql, ipywidgets, jupyter-console, spanner-graph-notebook\n",
            "Loaded 8000 samples from 16 episodes\n",
            "Loaded 2000 samples from 4 episodes\n",
            "pred.shape: torch.Size([128, 3, 2]) target.shape: torch.Size([128, 3, 2])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "The size of tensor a (128) must match the size of tensor b (3) at non-singleton dimension 1",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4183620644.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1e-2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     train(\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"mlp_planner\"\u001b[0m\u001b[0;34m,\u001b[0m        \u001b[0;31m# or \"mlp_planner\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mtransform_pipeline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"state_only\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/online_deep_learning/homework4/homework/train_planner.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model_name, transform_pipeline, num_workers, lr, batch_size, num_epoch, device)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mwaypoint_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \"\"\"\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mpred\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_waypoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mmask\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_waypoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/online_deep_learning/homework4/homework/train_planner.py\u001b[0m in \u001b[0;36mwaypoint_loss\u001b[0;34m(pred, target, mask)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;31m# ------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;31m# Waypoint loss (weighted Long/Lat + mask)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# ------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (128) must match the size of tensor b (3) at non-singleton dimension 1"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# refreshes python imports automatically when you edit the source file\n",
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "from homework.train_planner import train\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "for lr in [1e-2, 1e-3, 1e-4]:\n",
        "    train(\n",
        "        model_name=\"mlp_planner\",        # or \"mlp_planner\"\n",
        "        transform_pipeline=\"state_only\",\n",
        "        num_workers=2,\n",
        "        lr=lr,\n",
        "        batch_size=128,\n",
        "        num_epoch=40,\n",
        "        device=device\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WODRADDO02Hd"
      },
      "source": [
        "## Grader\n",
        "\n",
        "Run the following cell to grade your homework.\n",
        "\n",
        "Note: if you don't set up PySuperTuxKart, the grader will not run the driving tests."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ijkV65Bvpaj"
      },
      "outputs": [],
      "source": [
        "!python3 -m grader homework -vv --disable_color\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETsTM1gF1dEf"
      },
      "source": [
        "## PySuperTuxKart Setup (Optional)\n",
        "\n",
        "We will use your trained planner to drive around in SuperTuxKart!  \n",
        "SuperTuxKart is a python wrapper around a C++ game, so it requires a few more build steps.\n",
        "\n",
        "This is optional to test locally - if your planner passes the local grader's tests for prediction accuracy, it should drive just fine and you can submit to the online grader. You only need to set up PySuperTuxKart locally if you want to see your model driving around."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMaRKXb9a9er"
      },
      "outputs": [],
      "source": [
        "# don't worry about the \"... is not a symbolic link\" logs\n",
        "!sudo DEBIAN_FRONTEND=noninteractive apt install -qq libnvidia-gl-535\n",
        "!pip install PySuperTuxKartData --index-url=https://www.cs.utexas.edu/~bzhou/dl_class/pystk\n",
        "!pip install PySuperTuxKart --index-url=https://www.cs.utexas.edu/~bzhou/dl_class/pystk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBroVMqYj_9b"
      },
      "source": [
        "## End to End Driving Visualization\n",
        "\n",
        "After your models are trained, you can see how they perform in game!\n",
        "\n",
        "Some of the driving might look \"jittery\", due to the simple logic of the controller (directly steer towards the predicted waypoints).\n",
        "\n",
        "You can always tweak the controller for fun, but note that we will use the original one for grading."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0KHa6JDIT5GP"
      },
      "outputs": [],
      "source": [
        "# This script will simply run your model and save the session as a video\n",
        "!python3 -m homework.supertux_utils.evaluate --model mlp_planner --track lighthouse --max-steps 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xtHZkEP8UxQF"
      },
      "outputs": [],
      "source": [
        "# This cell displays the videos\n",
        "from IPython.display import Video\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "video_dir = Path(\"videos\")\n",
        "\n",
        "for video_path in sorted(video_dir.glob(\"*.mp4\")):\n",
        "    print(video_path)\n",
        "    display(Video(video_path, embed=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiCe-RX-J6CF"
      },
      "source": [
        "## Update your changes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eMF7LKEoldcx"
      },
      "outputs": [],
      "source": [
        "%ls\n",
        "!git status\n",
        "\n",
        "# Be careful not to \"git add *\" since there are datasets and logs\n",
        "!git add homework/*.py\n",
        "!git config --global user.email \"GITHUB_EMAIL\"\n",
        "!git config --global user.name \"GITHUB_USER\"\n",
        "!git commit -m \"update\"\n",
        "!git push origin main"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxbPtnF55AMU"
      },
      "source": [
        "## Submission\n",
        "\n",
        "Run the following cell to bundle your submission (modify UTID accordingly).\n",
        "\n",
        "If you notice that your bundle is too large, you can modify the `bundle.py` script and ignore large files by adding them manually to `BLACKLIST`.\n",
        "\n",
        "After the bundler and grader run, right click and download your bundled `.zip` file from the Colab UI.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M07WA1Os4Xxh"
      },
      "outputs": [],
      "source": [
        "!python3 bundle.py homework UTID\n",
        "\n",
        "# optional: run the grader with your bundled homework to double check\n",
        "!python3 -m grader UTID.zip -vv --disable_color"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glE1RHxE30_u"
      },
      "source": [
        "## Tensorboard (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wRWuQIERv6hz"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "usjJKjTUQQqT"
      },
      "outputs": [],
      "source": [
        "!sudo DEBIAN_FRONTEND=noninteractive apt install -qq libnvidia-gl-535\n",
        "!pip install PySuperTuxKartData --index-url=https://www.cs.utexas.edu/~bzhou/dl_class/pystk -vv\n",
        "!pip install PySuperTuxKart --index-url=https://www.cs.utexas.edu/~bzhou/dl_class/pystk -vv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MHCjN-1hRsxt"
      },
      "outputs": [],
      "source": [
        "!python -v"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}