{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zWseivb1lli"
      },
      "source": [
        "## General Colab Tips\n",
        "- Modify files by opening/editing them in the UI (double-click to open).\n",
        "- `Right click > Refresh` in the Colab file explorer to update the directory.\n",
        "- All files are lost when the Colab session disconnects, so make sure back up your work.\n",
        "- Do **not** use `drive.mount` for your datasets! Reading from GDrive is super slow.\n",
        "- Instead, place datasets into the `/content/` folder and modify your data accordingly.\n",
        "\n",
        "**Make a copy of this notebook and modify this to whatever workflow you prefer!**\n",
        "\n",
        "If you have some additional colab tips, please share them on the discussion forum.\n",
        "\n",
        "## Setup\n",
        "\n",
        "First, enable a GPU runtime via `Runtime > Change runtime type > T4 GPU`\n",
        "\n",
        "Next, upload the your project files to the Colab. You can do this by either\n",
        "- using Github (**recommended**)\n",
        "- uploading files manually using the UI\n",
        "\n",
        "## Github Setup\n",
        "\n",
        "You can use git from within Google Colab!\n",
        "\n",
        "For this section, we assume you know how to use git and have already pushed the starter code to a private repo.\n",
        "\n",
        "Before you continue, make sure you download and push the starter code to your repo.  \n",
        "It's a good idea to structure your repo something like\n",
        "```\n",
        "online_deep_learning/\n",
        "    homework1/\n",
        "    homework2/\n",
        "    ...\n",
        "```\n",
        "\n",
        "We highly recommend using this workflow as you'll be able to easily pull/commit your changes after modifying your model on Colab.\n",
        "\n",
        "To do this, you'll need a personal access token from [https://github.com/settings/tokens](https://github.com/settings/tokens)\n",
        "\n",
        "The easiest thing to do is select \"classic\" token and make sure you have the `repo` scope selected to allow access to your private repos.\n",
        "There's also fine-grained tokens where you can select access to specific repos.\n",
        "\n",
        "Once you have your token, fill in your information and then run the following cell to clone your git repo to the Colab instance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "vLC51taXudfJ",
        "outputId": "9f46c487-d2a3-4cc7-bd80-999a25ea98ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
            "/content\n",
            "Cloning into 'online_deep_learning'...\n",
            "remote: Enumerating objects: 1493, done.\u001b[K\n",
            "remote: Counting objects: 100% (192/192), done.\u001b[K\n",
            "remote: Compressing objects: 100% (191/191), done.\u001b[K\n",
            "remote: Total 1493 (delta 145), reused 1 (delta 1), pack-reused 1301 (from 5)\u001b[K\n",
            "Receiving objects: 100% (1493/1493), 3.87 MiB | 8.00 MiB/s, done.\n",
            "Resolving deltas: 100% (1054/1054), done.\n",
            "\u001b[0m\u001b[01;34monline_deep_learning\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "\n",
        "os.environ['USER'] = 'thisisanu'\n",
        "os.environ['REPO'] = 'online_deep_learning'\n",
        "os.environ['TOKEN'] = 'ithub_pat_11BIG54WA0sAoSEImPXImB_OUcAjo84vwWTugnGOH4GbPnqToNKRJESKhyxDDzjYYUDQXP7HGCBmOPHCVt'\n",
        "\n",
        "# do everything in colab's \"root\" directory\n",
        "!rm -rf /content/online_deep_learning\n",
        "!rm -rf /content/online_deep_learning/homework4\n",
        "\n",
        "%cd /content\n",
        "!git clone https://${TOKEN}@github.com/${USER}/${REPO}.git\n",
        "\n",
        "# make sure your repo shows up\n",
        "%ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gxzo13BN6FL0"
      },
      "source": [
        "## Code Setup\n",
        "\n",
        "Move into `homework4/` so we can continue setting up the data / code for training.\n",
        "\n",
        "This will be the main working directory and the training/grading must be run from this directory.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "et3KFSXs3IHk",
        "outputId": "06bc26d2-26d4-4c71-8bf2-c86444f02e10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/online_deep_learning\n",
            "gitignore  \u001b[0m\u001b[01;34mhomework1\u001b[0m/  \u001b[01;34mhomework2\u001b[0m/  \u001b[01;34mhomework3\u001b[0m/  \u001b[01;34mhomework4\u001b[0m/  README.md\n",
            "/content/online_deep_learning/homework4\n",
            "\u001b[0m\u001b[01;34massets\u001b[0m/    \u001b[01;34mgrader\u001b[0m/    Homework_4.ipynb  requirements.txt\n",
            "bundle.py  \u001b[01;34mhomework\u001b[0m/  README.md\n"
          ]
        }
      ],
      "source": [
        "# navigate to your repo\n",
        "%cd /content/{os.environ['REPO']}\n",
        "%ls\n",
        "\n",
        "# go to a specific homework\n",
        "%cd homework4\n",
        "%ls\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnjXUhBY7x_E"
      },
      "source": [
        "## Dataset Setup\n",
        "\n",
        "Now that your code is all ready, the next step is to download the datasets.\n",
        "\n",
        "Note: it's good practice to add data directories like `*/drive_data` to your `.gitignore` so you don't accidently commit them to your repo.\n",
        "\n",
        "Since the datasets used in this class are relatively small, we can simply re-download them if the compute instance crashes/restarts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "RmMw_Zoa8Ljm",
        "outputId": "1656d429-2667-4d03-aa0f-29e369d3388c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34massets\u001b[0m/    \u001b[01;34mdrive_data\u001b[0m/     \u001b[01;34mgrader\u001b[0m/    Homework_4.ipynb  requirements.txt\n",
            "bundle.py  drive_data.zip  \u001b[01;34mhomework\u001b[0m/  README.md\n",
            "Requirement already satisfied: matplotlib>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (3.10.0)\n",
            "Requirement already satisfied: Pillow>=10.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (11.3.0)\n",
            "Requirement already satisfied: tensorboard>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (2.19.0)\n",
            "Requirement already satisfied: termcolor==2.4.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (2.4.0)\n",
            "Requirement already satisfied: opencv-python>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (4.12.0.88)\n",
            "Requirement already satisfied: tqdm==4.66.4 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (4.66.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.5.0->-r requirements.txt (line 1)) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.5.0->-r requirements.txt (line 1)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.5.0->-r requirements.txt (line 1)) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.5.0->-r requirements.txt (line 1)) (1.4.9)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.5.0->-r requirements.txt (line 1)) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.5.0->-r requirements.txt (line 1)) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.5.0->-r requirements.txt (line 1)) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.5.0->-r requirements.txt (line 1)) (2.9.0.post0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.0.0->-r requirements.txt (line 3)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.0.0->-r requirements.txt (line 3)) (1.76.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.0.0->-r requirements.txt (line 3)) (3.10)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.0.0->-r requirements.txt (line 3)) (5.29.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.0.0->-r requirements.txt (line 3)) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.0.0->-r requirements.txt (line 3)) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.0.0->-r requirements.txt (line 3)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.0.0->-r requirements.txt (line 3)) (3.1.3)\n",
            "Requirement already satisfied: typing-extensions~=4.12 in /usr/local/lib/python3.12/dist-packages (from grpcio>=1.48.2->tensorboard>=2.0.0->-r requirements.txt (line 3)) (4.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.0.0->-r requirements.txt (line 3)) (3.0.3)\n",
            "Requirement already satisfied: ipython>=8.20.0 in /usr/local/lib/python3.12/dist-packages (9.8.0)\n",
            "Requirement already satisfied: decorator>=4.3.2 in /usr/local/lib/python3.12/dist-packages (from ipython>=8.20.0) (4.4.2)\n",
            "Requirement already satisfied: ipython-pygments-lexers>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython>=8.20.0) (1.1.1)\n",
            "Requirement already satisfied: jedi>=0.18.1 in /usr/local/lib/python3.12/dist-packages (from ipython>=8.20.0) (0.19.2)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1.5 in /usr/local/lib/python3.12/dist-packages (from ipython>=8.20.0) (0.2.1)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython>=8.20.0) (4.9.0)\n",
            "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /usr/local/lib/python3.12/dist-packages (from ipython>=8.20.0) (3.0.52)\n",
            "Requirement already satisfied: pygments>=2.11.0 in /usr/local/lib/python3.12/dist-packages (from ipython>=8.20.0) (2.19.2)\n",
            "Requirement already satisfied: stack_data>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from ipython>=8.20.0) (0.6.3)\n",
            "Requirement already satisfied: traitlets>=5.13.0 in /usr/local/lib/python3.12/dist-packages (from ipython>=8.20.0) (5.14.3)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.18.1->ipython>=8.20.0) (0.8.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython>=8.20.0) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=8.20.0) (0.2.14)\n",
            "Requirement already satisfied: executing>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from stack_data>=0.6.0->ipython>=8.20.0) (2.2.1)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from stack_data>=0.6.0->ipython>=8.20.0) (3.0.1)\n",
            "Requirement already satisfied: pure-eval in /usr/local/lib/python3.12/dist-packages (from stack_data>=0.6.0->ipython>=8.20.0) (0.2.3)\n",
            "Python: 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n",
            "Executable: /usr/bin/python3\n",
            "Name: ipython\n",
            "Version: 9.8.0\n",
            "Summary: IPython: Productive Interactive Computing\n",
            "Home-page: https://ipython.org\n",
            "Author: The IPython Development Team\n",
            "Author-email: ipython-dev@python.org\n",
            "License: \n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: decorator, ipython-pygments-lexers, jedi, matplotlib-inline, pexpect, prompt_toolkit, pygments, stack_data, traitlets\n",
            "Required-by: bigquery-magics, cufflinks, google-colab, ipykernel, ipyparallel, ipython-sql, ipywidgets, jupyter-console, spanner-graph-notebook\n"
          ]
        }
      ],
      "source": [
        "!rm -rf drive_data\n",
        "!curl -s -L https://www.cs.utexas.edu/~bzhou/dl_class/drive_data.zip -o ./drive_data.zip && unzip -qo drive_data.zip\n",
        "%ls\n",
        "\n",
        "import sys\n",
        "import torch\n",
        "\n",
        "!{sys.executable} -m pip install -r requirements.txt\n",
        "!{sys.executable} -m pip install --upgrade \"ipython>=8.20.0\"\n",
        "\n",
        "print(\"Python:\", sys.version)\n",
        "print(\"Executable:\", sys.executable)\n",
        "\n",
        "!pip show ipython"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUR0D6BsJP49"
      },
      "source": [
        "## Model Implementation + Training\n",
        "\n",
        "Now you should be all set up.\n",
        "Next, you'll need to implement\n",
        "- `homework/train_planner.py`\n",
        "- `homework/models.py`\n",
        "\n",
        "And then you're ready to train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WLe2Ti0xJeIL",
        "outputId": "ab1dcfcf-83a1-4b56-c5e8-7a58e4e5ec51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Training mlp_planner ===\n",
            "\n",
            "Using device: cpu\n",
            "Model: mlp_planner\n",
            "Loaded 8000 samples from 16 episodes\n",
            "Loaded 2000 samples from 4 episodes\n",
            "Using weighted MSE loss for better lateral error performance\n",
            "Using AdamW optimizer, lr=0.0003, weight_decay=0.001\n",
            "Starting training...\n",
            "Epoch 1/50: Train Loss: 66.2435, Val Long Error: 0.2225, Val Lat Error: 3.0856, LR: 0.000300\n",
            "New best lateral error: 3.0856\n",
            "New best longitudinal error: 0.2225\n",
            "Saved model → /content/online_deep_learning/homework4/homework/mlp_planner.th\n",
            "Saved best model to /content/online_deep_learning/homework4/homework/mlp_planner.th\n",
            "Epoch 2/50: Train Loss: 27.6464, Val Long Error: 0.2336, Val Lat Error: 0.9186, LR: 0.000300\n",
            "New best lateral error: 0.9186\n",
            "Saved model → /content/online_deep_learning/homework4/homework/mlp_planner.th\n",
            "Saved best model to /content/online_deep_learning/homework4/homework/mlp_planner.th\n",
            "Epoch 3/50: Train Loss: 9.8264, Val Long Error: 0.1672, Val Lat Error: 0.4796, LR: 0.000300\n",
            "New best lateral error: 0.4796\n",
            "New best longitudinal error: 0.1672\n",
            "Saved model → /content/online_deep_learning/homework4/homework/mlp_planner.th\n",
            "Saved best model to /content/online_deep_learning/homework4/homework/mlp_planner.th\n",
            "Epoch 4/50: Train Loss: 8.8790, Val Long Error: 0.1577, Val Lat Error: 0.6617, LR: 0.000300\n",
            "Epoch 5/50: Train Loss: 8.4305, Val Long Error: 0.1444, Val Lat Error: 0.6583, LR: 0.000300\n",
            "Epoch 6/50: Train Loss: 8.2632, Val Long Error: 0.1547, Val Lat Error: 0.6666, LR: 0.000300\n",
            "Epoch 7/50: Train Loss: 8.2249, Val Long Error: 0.1409, Val Lat Error: 0.8029, LR: 0.000210\n",
            "Epoch 8/50: Train Loss: 8.1501, Val Long Error: 0.1463, Val Lat Error: 0.7341, LR: 0.000210\n",
            "Epoch 9/50: Train Loss: 8.2163, Val Long Error: 0.1367, Val Lat Error: 0.8996, LR: 0.000210\n",
            "Epoch 10/50: Train Loss: 8.1138, Val Long Error: 0.1400, Val Lat Error: 0.6407, LR: 0.000210\n",
            "Epoch 11/50: Train Loss: 7.9875, Val Long Error: 0.1447, Val Lat Error: 0.8017, LR: 0.000147\n",
            "Epoch 12/50: Train Loss: 7.9054, Val Long Error: 0.1353, Val Lat Error: 0.7812, LR: 0.000147\n",
            "Epoch 13/50: Train Loss: 7.8718, Val Long Error: 0.1338, Val Lat Error: 0.6959, LR: 0.000147\n",
            "Epoch 14/50: Train Loss: 7.8271, Val Long Error: 0.1332, Val Lat Error: 0.7710, LR: 0.000147\n",
            "Epoch 15/50: Train Loss: 7.8541, Val Long Error: 0.1391, Val Lat Error: 0.7192, LR: 0.000103\n",
            "Epoch 16/50: Train Loss: 7.8551, Val Long Error: 0.1360, Val Lat Error: 0.7667, LR: 0.000103\n",
            "Epoch 17/50: Train Loss: 7.7933, Val Long Error: 0.1341, Val Lat Error: 0.6756, LR: 0.000103\n",
            "Epoch 18/50: Train Loss: 7.7467, Val Long Error: 0.1356, Val Lat Error: 0.6740, LR: 0.000103\n",
            "Epoch 19/50: Train Loss: 7.7332, Val Long Error: 0.1347, Val Lat Error: 0.8059, LR: 0.000072\n",
            "Epoch 20/50: Train Loss: 7.8328, Val Long Error: 0.1328, Val Lat Error: 0.7767, LR: 0.000072\n",
            "Epoch 21/50: Train Loss: 7.7021, Val Long Error: 0.1355, Val Lat Error: 0.7206, LR: 0.000072\n",
            "Epoch 22/50: Train Loss: 7.7247, Val Long Error: 0.1379, Val Lat Error: 0.7148, LR: 0.000072\n",
            "Epoch 23/50: Train Loss: 7.6751, Val Long Error: 0.1349, Val Lat Error: 0.7733, LR: 0.000050\n",
            "Epoch 24/50: Train Loss: 7.6128, Val Long Error: 0.1326, Val Lat Error: 0.7466, LR: 0.000050\n",
            "Epoch 25/50: Train Loss: 7.6713, Val Long Error: 0.1341, Val Lat Error: 0.7155, LR: 0.000050\n",
            "Epoch 26/50: Train Loss: 7.7126, Val Long Error: 0.1358, Val Lat Error: 0.7918, LR: 0.000050\n",
            "Epoch 27/50: Train Loss: 7.6460, Val Long Error: 0.1329, Val Lat Error: 0.7465, LR: 0.000035\n",
            "Epoch 28/50: Train Loss: 7.7365, Val Long Error: 0.1349, Val Lat Error: 0.7710, LR: 0.000035\n",
            "Epoch 29/50: Train Loss: 7.6141, Val Long Error: 0.1347, Val Lat Error: 0.7860, LR: 0.000035\n",
            "Epoch 30/50: Train Loss: 7.6953, Val Long Error: 0.1337, Val Lat Error: 0.7924, LR: 0.000035\n",
            "Epoch 31/50: Train Loss: 7.6351, Val Long Error: 0.1358, Val Lat Error: 0.7264, LR: 0.000025\n",
            "Epoch 32/50: Train Loss: 7.6424, Val Long Error: 0.1332, Val Lat Error: 0.7548, LR: 0.000025\n",
            "Epoch 33/50: Train Loss: 7.5913, Val Long Error: 0.1337, Val Lat Error: 0.7631, LR: 0.000025\n",
            "Epoch 34/50: Train Loss: 7.5695, Val Long Error: 0.1372, Val Lat Error: 0.7066, LR: 0.000025\n",
            "Epoch 35/50: Train Loss: 7.5669, Val Long Error: 0.1345, Val Lat Error: 0.7892, LR: 0.000017\n",
            "Epoch 36/50: Train Loss: 7.6309, Val Long Error: 0.1354, Val Lat Error: 0.7949, LR: 0.000017\n",
            "Epoch 37/50: Train Loss: 7.7319, Val Long Error: 0.1358, Val Lat Error: 0.7221, LR: 0.000017\n",
            "Epoch 38/50: Train Loss: 7.6318, Val Long Error: 0.1345, Val Lat Error: 0.7592, LR: 0.000017\n",
            "Epoch 39/50: Train Loss: 7.7196, Val Long Error: 0.1328, Val Lat Error: 0.7143, LR: 0.000012\n",
            "Epoch 40/50: Train Loss: 7.6739, Val Long Error: 0.1335, Val Lat Error: 0.7655, LR: 0.000012\n",
            "Epoch 41/50: Train Loss: 7.6354, Val Long Error: 0.1353, Val Lat Error: 0.7611, LR: 0.000012\n",
            "Epoch 42/50: Train Loss: 7.6198, Val Long Error: 0.1365, Val Lat Error: 0.7540, LR: 0.000012\n",
            "Epoch 43/50: Train Loss: 7.6256, Val Long Error: 0.1371, Val Lat Error: 0.7505, LR: 0.000008\n",
            "Epoch 44/50: Train Loss: 7.5972, Val Long Error: 0.1331, Val Lat Error: 0.7818, LR: 0.000008\n",
            "Epoch 45/50: Train Loss: 7.6032, Val Long Error: 0.1349, Val Lat Error: 0.7428, LR: 0.000008\n",
            "Epoch 46/50: Train Loss: 7.6217, Val Long Error: 0.1320, Val Lat Error: 0.7467, LR: 0.000008\n",
            "Epoch 47/50: Train Loss: 7.5203, Val Long Error: 0.1333, Val Lat Error: 0.7365, LR: 0.000006\n",
            "Epoch 48/50: Train Loss: 7.7314, Val Long Error: 0.1342, Val Lat Error: 0.7525, LR: 0.000006\n",
            "Epoch 49/50: Train Loss: 7.5260, Val Long Error: 0.1340, Val Lat Error: 0.7409, LR: 0.000006\n",
            "Epoch 50/50: Train Loss: 7.5973, Val Long Error: 0.1325, Val Lat Error: 0.7528, LR: 0.000006\n",
            "Training completed!\n",
            "Best lateral error: 0.4796\n",
            "Best longitudinal error: 0.1672\n",
            "\n",
            "=== Training transformer_planner ===\n",
            "\n",
            "Forcing CPU for transformer model to avoid MPS buffer issues\n",
            "Using device: cpu\n",
            "Reduced batch size to 8 for transformer model\n",
            "Model: transformer_planner\n",
            "Loaded 8000 samples from 16 episodes\n",
            "Loaded 2000 samples from 4 episodes\n",
            "Using weighted MSE loss for better lateral error performance\n",
            "Using AdamW optimizer, lr=0.0001, weight_decay=0.001\n",
            "Starting training...\n",
            "Epoch 1/50: Train Loss: 14.1229, Val Long Error: 0.1686, Val Lat Error: 0.6805, LR: 0.000100\n",
            "New best lateral error: 0.6805\n",
            "New best longitudinal error: 0.1686\n",
            "Saved model → /content/online_deep_learning/homework4/homework/transformer_planner.th\n",
            "Saved best model to /content/online_deep_learning/homework4/homework/transformer_planner.th\n",
            "Epoch 2/50: Train Loss: 9.9232, Val Long Error: 0.1985, Val Lat Error: 0.6331, LR: 0.000100\n",
            "New best lateral error: 0.6331\n",
            "Saved model → /content/online_deep_learning/homework4/homework/transformer_planner.th\n",
            "Saved best model to /content/online_deep_learning/homework4/homework/transformer_planner.th\n",
            "Epoch 3/50: Train Loss: 9.4213, Val Long Error: 0.1467, Val Lat Error: 1.0432, LR: 0.000100\n",
            "Epoch 4/50: Train Loss: 9.0919, Val Long Error: 0.1436, Val Lat Error: 1.1195, LR: 0.000100\n",
            "Epoch 5/50: Train Loss: 9.0322, Val Long Error: 0.1436, Val Lat Error: 0.6813, LR: 0.000100\n",
            "Epoch 6/50: Train Loss: 9.0511, Val Long Error: 0.1399, Val Lat Error: 0.5780, LR: 0.000100\n",
            "New best lateral error: 0.5780\n",
            "New best longitudinal error: 0.1399\n",
            "Saved model → /content/online_deep_learning/homework4/homework/transformer_planner.th\n",
            "Saved best model to /content/online_deep_learning/homework4/homework/transformer_planner.th\n",
            "Epoch 7/50: Train Loss: 8.9216, Val Long Error: 0.1524, Val Lat Error: 1.1793, LR: 0.000100\n",
            "Epoch 8/50: Train Loss: 8.9274, Val Long Error: 0.1463, Val Lat Error: 0.9610, LR: 0.000100\n",
            "Epoch 9/50: Train Loss: 8.8584, Val Long Error: 0.1471, Val Lat Error: 1.1050, LR: 0.000100\n",
            "Epoch 10/50: Train Loss: 8.8309, Val Long Error: 0.1408, Val Lat Error: 0.5921, LR: 0.000070\n",
            "Epoch 11/50: Train Loss: 8.7565, Val Long Error: 0.1410, Val Lat Error: 0.9129, LR: 0.000070\n",
            "Epoch 12/50: Train Loss: 8.5632, Val Long Error: 0.1442, Val Lat Error: 1.0714, LR: 0.000070\n",
            "Epoch 13/50: Train Loss: 8.7264, Val Long Error: 0.1440, Val Lat Error: 0.8130, LR: 0.000070\n"
          ]
        }
      ],
      "source": [
        "# ---------------------------------------------------------------\n",
        "# Full MLPPlanner training snippet\n",
        "# ---------------------------------------------------------------\n",
        "\n",
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import torch\n",
        "from homework.train_planner import train\n",
        "\n",
        "# Use GPU if available, else CPU\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Training configuration (common settings)\n",
        "train_config = {\n",
        "    \"transform_pipeline\": \"state_only\",  # for MLP and Transformer\n",
        "    \"num_workers\": 2,\n",
        "    \"lr\": 3e-4,\n",
        "    \"batch_size\": 128,\n",
        "    \"num_epoch\": 40,\n",
        "    \"device\": device,\n",
        "}\n",
        "\n",
        "# List of planners to train\n",
        "planners = [\"mlp_planner\", \"transformer_planner\", \"cnn_planner\"]\n",
        "\n",
        "for planner_name in planners:\n",
        "    print(f\"\\n=== Training {planner_name} ===\\n\")\n",
        "\n",
        "    # Update the model name in config\n",
        "    train_config[\"model_name\"] = planner_name\n",
        "\n",
        "    # For CNNPlanner, use \"image_only\" transform\n",
        "    train_config[\"transform_pipeline\"] = \"state_only\"\n",
        "\n",
        "    # Start training\n",
        "    train(**train_config)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WODRADDO02Hd"
      },
      "source": [
        "## Grader\n",
        "\n",
        "Run the following cell to grade your homework.\n",
        "\n",
        "Note: if you don't set up PySuperTuxKart, the grader will not run the driving tests."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ijkV65Bvpaj"
      },
      "outputs": [],
      "source": [
        "!cd /content/online_deep_learning/homework4/homework\n",
        "!python3 -m grader homework -vv --disable_color\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETsTM1gF1dEf"
      },
      "source": [
        "## PySuperTuxKart Setup (Optional)\n",
        "\n",
        "We will use your trained planner to drive around in SuperTuxKart!  \n",
        "SuperTuxKart is a python wrapper around a C++ game, so it requires a few more build steps.\n",
        "\n",
        "This is optional to test locally - if your planner passes the local grader's tests for prediction accuracy, it should drive just fine and you can submit to the online grader. You only need to set up PySuperTuxKart locally if you want to see your model driving around."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMaRKXb9a9er",
        "outputId": "252be9b3-0f41-48d6-befa-b8db984f3122",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The following additional packages will be installed:\n",
            "  libnvidia-common-535\n",
            "The following NEW packages will be installed:\n",
            "  libnvidia-common-535 libnvidia-gl-535\n",
            "0 upgraded, 2 newly installed, 0 to remove and 41 not upgraded.\n",
            "Need to get 183 MB of archives.\n",
            "After this operation, 464 MB of additional disk space will be used.\n",
            "Selecting previously unselected package libnvidia-common-535.\n",
            "(Reading database ... 121713 files and directories currently installed.)\n",
            "Preparing to unpack .../libnvidia-common-535_535.274.02-0ubuntu1_all.deb ...\n",
            "Unpacking libnvidia-common-535 (535.274.02-0ubuntu1) ...\n",
            "Selecting previously unselected package libnvidia-gl-535:amd64.\n",
            "Preparing to unpack .../libnvidia-gl-535_535.274.02-0ubuntu1_amd64.deb ...\n",
            "\u001b[1mdpkg-query:\u001b[0m no packages found matching libnvidia-gl-450\n",
            "Unpacking libnvidia-gl-535:amd64 (535.274.02-0ubuntu1) ...\n",
            "Setting up libnvidia-common-535 (535.274.02-0ubuntu1) ...\n",
            "Setting up libnvidia-gl-535:amd64 (535.274.02-0ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "Looking in indexes: https://www.cs.utexas.edu/~bzhou/dl_class/pystk\n",
            "Collecting PySuperTuxKartData\n",
            "  Downloading https://www.cs.utexas.edu/~bzhou/dl_class/pystk/pysupertuxkartdata/PySuperTuxKartData-1.0.1-py3-none-any.whl (620.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m620.7/620.7 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from PySuperTuxKartData) (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->PySuperTuxKartData) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->PySuperTuxKartData) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->PySuperTuxKartData) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->PySuperTuxKartData) (2025.11.12)\n",
            "Installing collected packages: PySuperTuxKartData\n",
            "Successfully installed PySuperTuxKartData-1.0.1\n",
            "Looking in indexes: https://www.cs.utexas.edu/~bzhou/dl_class/pystk\n",
            "Collecting PySuperTuxKart\n",
            "  Downloading https://www.cs.utexas.edu/~bzhou/dl_class/pystk/pysupertuxkart/pysupertuxkart-1.1.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PySuperTuxKartData in /usr/local/lib/python3.12/dist-packages (from PySuperTuxKart) (1.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from PySuperTuxKartData->PySuperTuxKart) (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->PySuperTuxKartData->PySuperTuxKart) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->PySuperTuxKartData->PySuperTuxKart) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->PySuperTuxKartData->PySuperTuxKart) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->PySuperTuxKartData->PySuperTuxKart) (2025.11.12)\n",
            "Installing collected packages: PySuperTuxKart\n",
            "Successfully installed PySuperTuxKart-1.1.3\n"
          ]
        }
      ],
      "source": [
        "# don't worry about the \"... is not a symbolic link\" logs\n",
        "!sudo DEBIAN_FRONTEND=noninteractive apt install -qq libnvidia-gl-535\n",
        "!pip install PySuperTuxKartData --index-url=https://www.cs.utexas.edu/~bzhou/dl_class/pystk\n",
        "!pip install PySuperTuxKart --index-url=https://www.cs.utexas.edu/~bzhou/dl_class/pystk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBroVMqYj_9b"
      },
      "source": [
        "## End to End Driving Visualization\n",
        "\n",
        "After your models are trained, you can see how they perform in game!\n",
        "\n",
        "Some of the driving might look \"jittery\", due to the simple logic of the controller (directly steer towards the predicted waypoints).\n",
        "\n",
        "You can always tweak the controller for fun, but note that we will use the original one for grading."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0KHa6JDIT5GP",
        "outputId": "788f7a20-ab9a-4f5b-8cd8-a9f54c696db2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"/content/online_deep_learning/homework4/homework/supertux_utils/evaluate.py\", line 297, in <module>\n",
            "    main()\n",
            "  File \"/content/online_deep_learning/homework4/homework/supertux_utils/evaluate.py\", line 278, in main\n",
            "    model = load_model(args.model, with_weights=True)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/online_deep_learning/homework4/homework/models.py\", line 137, in load_model\n",
            "    assert model_path.exists(), f\"{model_path.name} not found\"\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: mlp_planner.th not found\n"
          ]
        }
      ],
      "source": [
        "# This script will simply run your model and save the session as a video\n",
        "!python3 -m homework.supertux_utils.evaluate --model mlp_planner --track lighthouse --max-steps 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xtHZkEP8UxQF"
      },
      "outputs": [],
      "source": [
        "# This cell displays the videos\n",
        "from IPython.display import Video\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "video_dir = Path(\"videos\")\n",
        "\n",
        "for video_path in sorted(video_dir.glob(\"*.mp4\")):\n",
        "    print(video_path)\n",
        "    display(Video(video_path, embed=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiCe-RX-J6CF"
      },
      "source": [
        "## Update your changes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eMF7LKEoldcx"
      },
      "outputs": [],
      "source": [
        "%ls\n",
        "!git status\n",
        "\n",
        "# Be careful not to \"git add *\" since there are datasets and logs\n",
        "!git add homework/*.py\n",
        "!git config --global user.email \"GITHUB_EMAIL\"\n",
        "!git config --global user.name \"GITHUB_USER\"\n",
        "!git commit -m \"update\"\n",
        "!git push origin main"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxbPtnF55AMU"
      },
      "source": [
        "## Submission\n",
        "\n",
        "Run the following cell to bundle your submission (modify UTID accordingly).\n",
        "\n",
        "If you notice that your bundle is too large, you can modify the `bundle.py` script and ignore large files by adding them manually to `BLACKLIST`.\n",
        "\n",
        "After the bundler and grader run, right click and download your bundled `.zip` file from the Colab UI.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M07WA1Os4Xxh"
      },
      "outputs": [],
      "source": [
        "!python3 bundle.py homework UTID\n",
        "\n",
        "# optional: run the grader with your bundled homework to double check\n",
        "!python3 -m grader UTID.zip -vv --disable_color"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glE1RHxE30_u"
      },
      "source": [
        "## Tensorboard (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wRWuQIERv6hz"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "usjJKjTUQQqT"
      },
      "outputs": [],
      "source": [
        "!sudo DEBIAN_FRONTEND=noninteractive apt install -qq libnvidia-gl-535\n",
        "!pip install PySuperTuxKartData --index-url=https://www.cs.utexas.edu/~bzhou/dl_class/pystk -vv\n",
        "!pip install PySuperTuxKart --index-url=https://www.cs.utexas.edu/~bzhou/dl_class/pystk -vv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MHCjN-1hRsxt"
      },
      "outputs": [],
      "source": [
        "!python -v"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}